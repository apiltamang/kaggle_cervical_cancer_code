{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from Executor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Vgg16 model loaded.\n",
      "Found 33 images belonging to 3 classes.\n",
      "Found 27 images belonging to 3 classes.\n",
      "initialized training data from: ../data/sample/train\n",
      "initialized validation data from: ../data/sample/valid\n",
      "found number of softmax classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Reset the model, and run same finetuning using precomputed conv. model outputs. See if they match...\n",
    "executor = ExecutorBuilder().\\\n",
    "    with_runID(\"first\").\\\n",
    "    and_().\\\n",
    "    with_Vgg16().\\\n",
    "    and_().\\\n",
    "    train_batch_size(2). \\\n",
    "    and_(). \\\n",
    "    learn_rate(0.001).\\\n",
    "    and_().\\\n",
    "    data_on_path(\"../data/sample/\").\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33, 512, 14, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Precompute conv_model outputs\n",
    "data_aug_generator = image.ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1,\n",
    "          shear_range=0.15, zoom_range=0.1, channel_shift_range=10, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# # data augmented train batches\n",
    "temp_train_batches = executor.vgg.get_batches(batch_size=executor.batch_size, gen=data_aug_generator, path=executor.train_path, shuffle=False, class_mode=None)\n",
    "\n",
    "train_precomputed = executor.conv_model.predict_generator(temp_train_batches, temp_train_batches.nb_sample)\n",
    "\n",
    "train_precomputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1105170d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/apil.tamang/anaconda3/envs/py27_theano_keras/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/apil.tamang/anaconda3/envs/py27_theano_keras/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/apil.tamang/anaconda3/envs/py27_theano_keras/lib/python2.7/site-packages/keras/engine/training.py\", line 425, in data_generator_task\n",
      "    generator_output = next(generator)\n",
      "  File \"/Users/apil.tamang/anaconda3/envs/py27_theano_keras/lib/python2.7/site-packages/keras/preprocessing/image.py\", line 593, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "  File \"/Users/apil.tamang/anaconda3/envs/py27_theano_keras/lib/python2.7/site-packages/keras/preprocessing/image.py\", line 441, in _flow_index\n",
      "    current_index = (self.batch_index * batch_size) % N\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_aug_generator.flow_from_directory(\n",
    "        '../data/full',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode=None)\n",
    "\n",
    "precompute = executor.conv_model.predict_generator(train_generator, train_generator.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
